<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Workshop Schedule - Day 2</title>
</head>
<body>
    <table>
        <thead>
            <tr>
                <th width="15%">Timeslot</th>
                <th>Speaker</th>
                <th width="68%">Schedule/Topic of the Talk</th>
            </tr>
        </thead>
        <tbody>
            <tr class="double-line session-header">
                <td colspan="3"><b>Students' Oral Presentation #1</b></td>
            </tr>
            <tr>
                <td>09:00 - 09:25</td>
                <td><b><a href="https://joongkyulee.com/" target="_blank">Joongkyu Lee</a></b><br>PhD Student<br><a href="https://gsds.snu.ac.kr/" target="_blank">SNU DS</a></td>
                <td><h3>Nearly Minimax Optimal Regret for Multinomial Logistic Bandit</h3></td>
            </tr>
            <tr>
                <td>09:25 - 09:30</td>
                <td><b>Short Break</b></td>
                <td></td>
            </tr>
            <tr>
                <td>09:30 - 09:55</td>
                <td><b><a href="https://nick-jhlee.github.io/" target="_blank">Junghyun Lee</a></b><br>PhD Student<br><a href="https://gsai.kaist.ac.kr/" target="_blank">KAIST AI</a></td>
                <td><h3>On Various Statistical Problems Arising from Preference Learning and RLHF + Misc. Theories</h3></td>
            </tr>
            <tr>
                <td>09:55 - 10:00</td>
                <td><b>Short Break</b></td>
                <td></td>
            </tr>
            <tr>
                <td>10:00 - 10:25</td>
                <td><b><a href="https://openreview.net/profile?id=~Uijeong_Jang1" target="_blank">Uijeong Jang</a></b><br>PhD Student<br><a href="https://www.math.snu.ac.kr/" target="_blank">SNU Math</a></td>
                <td><h3>Computer-Assisted Design of Accelerated Composite Optimization Methods: OptISTA</h3></td>
            </tr>
            <tr>
                <td>10:25 - 10:30</td>
                <td><b>Short Break</b></td>
                <td></td>
            </tr>
            <tr class="double-line session-header">
                <td>10:30 - 12:00</td>
                <td colspan="3"><b>Poster Session #2</b></td>
            </tr>
            <tr>
                <td>12:00 - 14:00</td>
                <td colspan="2"><b><b>Lunch:</b> 농촌순두부 (낙지얼큰 + 초당)</b></td>
                <td></td>
            </tr>
            <tr class="double-line session-header">
                <td colspan="3"><b>Students' Oral Presentation #2</b></td>
            </tr>
            <tr>
                <td>14:00 - 14:25</td>
                <td><b><a href="https://id8198.github.io/" target="_blank">Jaewook Lee</a></b><br>MSc Student<br><a href="https://gsai.kaist.ac.kr/" target="_blank">KAIST AI</a></td>
                <td><h3>Exploiting Coordinate Structures in Optimization Problems</h3></td>
            </tr>
            <tr>
                <td>14:25 - 14:30</td>
                <td><b>Short Break</b></td>
                <td></td>
            </tr>
            <tr>
                <td>14:30 - 14:55</td>
                <td><b><a href="https://tetrzim.github.io/" target="_blank">TaeHo Yoon</a></b><br>PhD Student<br><a href="https://www.math.snu.ac.kr/" target="_blank">SNU Math</a></td>
                <td><h3>Optimal Acceleration for Minimax and Fixed-Point Problems is Not Unique <br> (ICML '24 Spotlight)</h3></td>
            </tr>
            <tr>
                <td>14:55 - 15:00</td>
                <td><b>Short Break</b></td>
                <td></td>
            </tr>
            <tr>
                <td>15:00 - 15:25</td>
                <td><b><a href="https://taehyunable.com/" target="_blank">Taehyun Hwang</a></b><br>PhD Student<br><a href="https://gsds.snu.ac.kr/" target="_blank">SNU DS</a></td>
                <td><h3>Lasso Bandit with Compatibility Condition on Optimal Arm</h3></td>
            </tr>
            <tr>
                <td>15:25 - 15:30</td>
                <td><b>Short Break</b></td>
                <td></td>
            </tr>
            <tr class="double-line session-header">
                <td>15:30 - 18:00</td>
                <td style="color:crimson" colspan="2"><b><b> Free Discussion</b></td>
            </tr>
            <tr class="double-line session-header">
                <td>18:00 - </td>
                <td colspan="2"><b><b>Dinner:</b> 초당우가 (과일먹은 돼지갈비)</b></td>
            </tr>
        </tbody>
    </table>

    <br>
    <h1>Students' Oral Presentation #1</h1>
            <div class="session-box">
            <div class="session-box">
                <div class="session-info">
                    <h3>Talk #1 (Joongkyu Lee): Nearly Minimax Optimal Regret for Multinomial Logistic Bandit
                </div>
                <div class="abstract">
                    <h4>Abstract:</h4>
                    <p>
                        In this paper, we study the contextual multinomial logit (MNL) bandit problem in which a learning agent sequentially selects 
                        an assortment based on contextual information, and user feedback follows an MNL choice model. 
                        There has been a significant discrepancy between lower and upper regret bounds, particularly regarding the maximum assortment size $K$. 
                        Additionally, the variation in reward structures between these bounds complicates the quest for optimality. 
                        Under uniform rewards, where all items have the same expected reward, we establish a regret lower bound of $\Omega(d\sqrt{\smash[b]{T/K}})$ 
                        and propose a constant-time algorithm, \texttt{MNL-UCB+}, that achieves a matching upper bound of $\tilde{\mathcal{O}}(d\sqrt{\smash[b]{T/K}})$. 
                        Under non-uniform rewards, we prove a lower bound of $\Omega(d\sqrt{T})$ and an upper bound of $\tilde{\mathcal{O}}(d\sqrt{T})$, 
                        also achievable by \texttt{MNL-UCB+}. Our empirical studies support these theoretical findings. 
                        To the best of our knowledge, this is the first work in the contextual MNL bandit literature to prove minimax optimality 
                        — for either uniform or non-uniform reward setting — and to propose a computationally efficient algorithm that achieves this optimality 
                        up to logarithmic factors.
                        This is a joint work with Prof. Min-hwan Oh (SNU DS) and is available at <a href="https://arxiv.org/abs/2405.09831" target="_blank">https://arxiv.org/abs/2405.09831</a>.
                    </p>
                </div>
            </div>

            <div class="session-box">
                <div class="session-info">
                    <h3>Talk #2 (Junghyun Lee): On Various Statistical Problems Arising from Preference Learning and RLHF + Misc. Theories</h3>
                </div>
                <div class="abstract">
                    <h4>Abstract:</h4>
                    <p>
                        In this talk, I will introduce my general research direction on addressing statistical and computational challenges arising/inspired 
                        from preference learning and RLHF, ultimately developing practically usable RLHF frameworks with provable statistical guarantees. 
                        My research consists of two parts. The first part analyzes RLHF-related interactive machine-learning problems, like bandits and RL, 
                        to improve the performance and understanding of RLHF. 
                        The second part of my research focuses on obtaining tight statistical guarantees for identifying and exploiting underlying 
                        low-dimensional structures in RLHF problems, enhancing interpretability, efficiency, and scalability. 
                        If time allows, I will also introduce my "other" theoretical works on fairness, optimization theory, and active learning.
                        The works mentioned in this talk can be found <a href="https://nick-jhlee.github.io/publication/#paper-conference" target="_blank"> here</a> and are joint work with my wonderful collaborators!
                    </p>
                </div>
            </div>

            <div class="session-box">
                <div class="session-info">
                    <h3>Talk #3 (Uijeong Jang): Computer-Assisted Design of Accelerated Composite Optimization Methods: OptISTA</h3>
                </div>
                <div class="abstract">
                    <h4>Abstract:</h4>
                    <p>
                        The accelerated composite optimization method FISTA (Beck, Teboulle 2009) is suboptimal, and we present a new method OptISTA that 
                        improves upon it by a factor of 2. The performance estimation problem (PEP) has recently been introduced as a new computer-assisted paradigm 
                        for designing optimal first-order methods, but the methodology was largely limited to unconstrained optimization with a single function. 
                        In this work, we present a novel double-function stepsize-optimization PEP methodology that poses the optimization over fixed-step 
                        first-order methods for composite optimization as a finite-dimensional nonconvex QCQP, which can be practically solved through spatial 
                        branch-and-bound algorithms, and use it to design the exact optimal method OptISTA for the composite optimization setup. 
                        We then establish the exact optimality of OptISTA with a novel lower bound construction that extends the semi-interpolated zero-chain 
                        construction (Drori, Taylor 2022) to the double-function setup of composite optimization. 
                        By establishing exact optimality, our work concludes the search for the fastest first-order methods for the proximal, projected-gradient, 
                        and proximal-gradient setups.
                        This is a joint work with Dr. Shuvomoy Das Gupta (MIT ORC &#8594; Columbia IEOR) and Prof. Ernest. K. Ryu (SNU Math), 
                        and is available at <a href="https://arxiv.org/abs/2305.15704" target="_blank">https://arxiv.org/abs/2305.15704</a>.
                    </p>
                </div>
            </div>
    </div>
    <br>

    <br>
    <h1>Poster Session #2</h1>
    <div class="session-box">
        <div class="poster">
            <h3 class="poster-title"><a href="https://arxiv.org/abs/2405.20165" target="_blank">Randomized Exploration for Reinforcement Learning with Multinomial Logistic Function Approximation</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>Wooseong Cho*, Taehyun Hwang*, Joongkyu Lee, and Min-hwan Oh</p>
                <h4>Abstract:</h4>
                <p>
                    We study reinforcement learning with multinomial logistic (MNL) function approximation where the underlying transition probability kernel 
                    of the Markov decision processes (MDPs) is parametrized by an unknown transition core with features of state and action. 
                    For the finite horizon episodic setting with inhomogeneous state transitions, we propose provably efficient algorithms 
                    with randomized exploration having frequentist regret guarantees. 
                    For our first algorithm, RRL-MNL, we adapt optimistic sampling to ensure the optimism of the estimated value function 
                    with sufficient frequency and establish that RRL-MNL is both statistically and computationally efficient, 
                    achieving a $\tilde{\mathcal{O}}(\kappa^{-1} d^{\frac{3}{2}} H^{\frac{3}{2}} \sqrt{T})$ frequentist regret bound with constant-time computational cost per episode. 
                    Here, $d$ is the dimension of the transition core, $H$ is the horizon length, $T$ is the total number of steps, and $\kappa$ is a problem-dependent constant. 
                    Despite the simplicity and practicality of RRL-MNL, $\kappa^{-1}$, which is potentially large in the worst case. 
                    To improve the dependence on $\kappa^{-1}$, we propose ORRL-MNL, which estimates the value function using local gradient information of the MNL transition model. 
                    We show that its frequentist regret bound is $\tilde{\mathcal{O}}(d^{\frac{3}{2}} H^{\frac{3}{2}} \sqrt{T} + \kappa^{-1} d^2 H^2)$. 
                    To the best of our knowledge, these are the first randomized RL algorithms for the MNL transition model that achieve both computational and statistical efficiency. 
                    Numerical experiments demonstrate the superior performance of the proposed algorithms.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title"><a href="https://arxiv.org/abs/2406.00823" target="_blank">Lasso Bandit with Compatibility Condition on Optimal Arm</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>Harin Lee*, Taehyun Hwang*, and Min-hwan Oh</p>
                <h4>Abstract:</h4>
                <p>
                    We consider a stochastic sparse linear bandit problem where only a sparse subset of context features affects the expected reward function, i.e., 
                    the unknown reward parameter has sparse structure. 
                    In the existing Lasso bandit literature, the compatibility conditions together with additional diversity conditions on the context features 
                    are imposed to achieve regret bounds that only depend logarithmically on the ambient dimension $d$. 
                    In this paper, we demonstrate that even without the additional diversity assumptions, the compatibility condition 
                    <i>only on the optimal arm</i> is sufficient to derive a regret bound that depends logarithmically on $d$, 
                    and our assumption is strictly weaker than those used in the lasso bandit literature under the single parameter setting. 
                    We propose an algorithm that adapts the forced-sampling technique and prove that the proposed algorithm achieves 
                    $\mathcal{O}(\text{poly}\log dT)$ regret under the margin condition. 
                    To our knowledge, the proposed algorithm requires the weakest assumptions among Lasso bandit algorithms under a single parameter setting 
                    that achieve $\mathcal{O}(\text{poly}\log dT)$ regret. 
                    Through the numerical experiments, we confirm the superior performance of our proposed algorithm.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title"><a href="https://arxiv.org/abs/2405.09831" target="_blank">Nearly Minimax Optimal Regret for Multinomial Logistic Bandit</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>Joongkyu Lee and Min-hwan Oh</p>
                <h4>Abstract:</h4>
                <p>
                    In this paper, we study the contextual multinomial logit (MNL) bandit problem in which a learning agent sequentially selects 
                    an assortment based on contextual information, and user feedback follows an MNL choice model. 
                    There has been a significant discrepancy between lower and upper regret bounds, particularly regarding the maximum assortment size $K$. 
                    Additionally, the variation in reward structures between these bounds complicates the quest for optimality. 
                    Under uniform rewards, where all items have the same expected reward, we establish a regret lower bound of $\Omega(d\sqrt{\smash[b]{T/K}})$ 
                    and propose a constant-time algorithm, \texttt{MNL-UCB+}, that achieves a matching upper bound of $\tilde{\mathcal{O}}(d\sqrt{\smash[b]{T/K}})$. 
                    Under non-uniform rewards, we prove a lower bound of $\Omega(d\sqrt{T})$ and an upper bound of $\tilde{\mathcal{O}}(d\sqrt{T})$, 
                    also achievable by \texttt{MNL-UCB+}. Our empirical studies support these theoretical findings. 
                    To the best of our knowledge, this is the first work in the contextual MNL bandit literature to prove minimax optimality 
                    — for either uniform or non-uniform reward setting — and to propose a computationally efficient algorithm that achieves this optimality 
                    up to logarithmic factors.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title"><a href="https://arxiv.org/abs/2305.15704" target="_blank">Computer-Assisted Design of Accelerated Composite Optimization Methods: OptISTA</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>
                    Uijeong Jang, Shuvomoy Das Gupta, and Ernest K. Ryu
                </p>
                <h4>Abstract:</h4>
                <p>
                    The accelerated composite optimization method FISTA (Beck, Teboulle 2009) is suboptimal, and we present a new method OptISTA that 
                    improves upon it by a factor of 2. The performance estimation problem (PEP) has recently been introduced as a new computer-assisted paradigm 
                    for designing optimal first-order methods, but the methodology was largely limited to unconstrained optimization with a single function. 
                    In this work, we present a novel double-function stepsize-optimization PEP methodology that poses the optimization over fixed-step 
                    first-order methods for composite optimization as a finite-dimensional nonconvex QCQP, which can be practically solved through spatial 
                    branch-and-bound algorithms, and use it to design the exact optimal method OptISTA for the composite optimization setup. 
                    We then establish the exact optimality of OptISTA with a novel lower bound construction that extends the semi-interpolated zero-chain 
                    construction (Drori, Taylor 2022) to the double-function setup of composite optimization. 
                    By establishing exact optimality, our work concludes the search for the fastest first-order methods for the proximal, projected-gradient, 
                    and proximal-gradient setups.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title">Atomic Visual Skills</h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Presenter:</h4>
                <p>
                    Hyunsik Chae
                </p>
                <h4>Abstract:</h4>
                <p>
                    Recent advancements in Vision Language Models (VLMs) like ChatGPT have highlighted their prowess in multi-modal reasoning tasks, 
                    yet these models falter at simple visual tasks involving basic geometric notions such as orthogonality and counting. 
                    This research contrasts these challenges with the known limitations of Large Language Models (LLMs) in basic arithmetic, 
                    underscoring a similar gap in VLMs for basic visual tasks. Unlike LLMs, there lacks a benchmark for assessing VLMs on these elementary skills. 
                    We aim to introduce a new benchmark that tests VLMs, including models like ChatGPT, Claude, and LLaVA, on fundamental visual concepts 
                    like angle acuteness, parallel lines, and convex shapes, which are intuitive to humans without formal calculations. 
                    Our early findings disclose significant deficiencies in VLMs' understanding of simple geometric principles, 
                    indicating that these basic perceptual skills are crucial for developing more sophisticated visual reasoning capabilities. 
                    We argue for a structured exploration of VLM capabilities in recognizing and processing basic visual information, 
                    moreover hypothesizing that complex visual reasoning builds upon these atomes of perceptual units.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title"><a href="https://openreview.net/forum?id=ZeF75iQcAc" target="_blank">Optimal Acceleration for Minimax and Fixed-Point Problems is Not Unique</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>TaeHo Yoon, Jaeyeon Kim, Jaewook J. Suh, and Ernest K. Ryu</p>
                <h4>Venue:</h4>
                <p>ICML '24 <b>Spotlight</b></p>
                <h4>Abstract:</h4>
                <p>
                    Recently, accelerated algorithms using the anchoring mechanism for minimax optimization and fixed-point problems have been proposed, 
                    and matching complexity lower bounds establish their optimality. 
                    In this work, we present the surprising observation that the optimal acceleration mechanism in minimax optimization and fixed-point problems 
                    is not unique. Our new algorithms achieve exactly the same worst-case convergence rates as existing anchor-based methods 
                    while using materially different acceleration mechanisms. 
                    Specifically, these new algorithms are dual to the prior anchor-based accelerated methods in the sense of H-duality. 
                    This finding opens a new avenue of research on accelerated algorithms since we now have a family of methods that 
                    empirically exhibit varied characteristics while having the same optimal worst-case guarantee.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title"><a href="https://arxiv.org/abs/2407.13977" target="_blank">A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>Junghyun Lee, Se-Young Yun, and Kwang-Sung Jun</p>
                <h4>Venue:</h4>
                <p><a href="https://arlet-workshop.github.io/" target="_blank">ICML '24 ARLET Workshop <b>Oral</b></a></p>
                <h4>Abstract:</h4>
                <p>
                    We present a unified likelihood ratio-based confidence sequence (CS) for any (self-concordant) generalized linear models (GLMs) 
                    that is guaranteed to be convex and numerically tight. 
                    We show that this is on par or improves upon known CSs for various GLMs, including Gaussian, Bernoulli, and Poisson. 
                    In particular, for the first time, our CS for Bernoulli has a poly(S)-free radius where S is the norm of the unknown parameter. 
                    Our first technical novelty is its derivation, which utilizes a time-uniform PAC-Bayesian bound with a uniform prior/posterior, 
                    despite the latter being a rather unpopular choice for deriving CSs. 
                    As a direct application of our new CS, we propose a simple and natural optimistic algorithm called OFUGLB applicable to 
                    any generalized linear bandits (GLB; Filippi et al. (2010)). 
                    Our analysis shows that the celebrated optimistic approach simultaneously attains state-of-the-art regrets for various self-concordant 
                    (not necessarily bounded) GLBs, and even poly(S)-free for bounded GLBs, including logistic bandits. 
                    The regret analysis, our second technical novelty, follows from combining our new CS with a new proof technique that completely avoids 
                    the previously widely used self-concordant control lemma (Faury et al., 2020, Lemma 9). 
                    Finally, we verify numerically that OFUGLB significantly outperforms the prior state-of-the-art (Lee et al., 2024) for logistic bandits.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title"><a href="https://openreview.net/forum?id=TW3ipYdDQG" target="_blank">Fundamental Benefit of Alternating Updates in Minimax Optimization</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>Jaewook Lee*, Hanseul Cho*, and Chulhee Yun</p>
                <h4>Venue:</h4>
                <p>ICML '24 <b>Spotlight</b></p>
                <h4>Abstract:</h4>
                <p>
                    The Gradient Descent-Ascent (GDA) algorithm, designed to solve minimax optimization problems, takes the descent and ascent steps either simultaneously (Sim-GDA) or alternately (Alt-GDA). 
                    While Alt-GDA is commonly observed to converge faster, the performance gap between the two is not yet well understood theoretically, especially in terms of global convergence rates. 
                    To address this theory-practice gap, we present fine-grained convergence analyses of both algorithms for strongly-convex-strongly-concave and Lipschitz-gradient objectives. 
                    Our new iteration complexity upper bound of Alt-GDA is strictly smaller than the lower bound of Sim-GDA; i.e., Alt-GDA is provably faster. 
                    Moreover, we propose Alternating-Extrapolation GDA (Alex-GDA), a general algorithmic framework that subsumes Sim-GDA and Alt-GDA, for which the main idea is 
                    to alternately take gradients from extrapolations of the iterates. 
                    We show that Alex-GDA satisfies a smaller iteration complexity bound, identical to that of the Extra-gradient method, while requiring less gradient computations. 
                    We also prove that Alex-GDA enjoys linear convergence for bilinear problems, for which both Sim-GDA and Alt-GDA fail to converge at all.
                </p>
            </div>
        </div>
        <div class="poster">
            <h3 class="poster-title"><a href="https://arxiv.org/abs/2405.20671" target="_blank">Position Coupling: Leveraging Task Structure for Improved Length Generalization of Transformers</a></h3>
            <button class="toggle-abstract show">Show Abstract</button>
            <div class="poster-abstract">
                <h4>Authors:</h4>
                <p>Hanseul Cho*, Jaeyoung Cha*, Pranjal Awasthi, Srinadh Bhojanapalli, Anumpam Gupta, and Chulhee Yun</p>
                <h4>Venue:</h4>
                <p><a href="https://longcontextfm.github.io/" target="_blank">ICML '24 LCFM Workshop</a></a></p>
                <h4>Abstract:</h4>
                <p>
                    Even for simple arithmetic tasks like integer addition, it is challenging for Transformers to generalize to longer sequences than those encountered during training. 
                    To tackle this problem, we propose position coupling, a simple yet effective method that directly embeds the structure of the tasks into the positional encoding 
                    of a (decoder-only) Transformer. 
                    Taking a departure from the vanilla absolute position mechanism assigning unique position IDs to each of the tokens, we assign the same position IDs to 
                    two or more "relevant" tokens; for integer addition tasks, we regard digits of the same significance as in the same position. 
                    On the empirical side, we show that with the proposed position coupling, a small (1-layer) Transformer trained on 1 to 30-digit additions can generalize 
                    up to 200-digit additions (6.67x of the trained length). 
                    On the theoretical side, we prove that a 1-layer Transformer with coupled positions can solve the addition task involving exponentially many digits, 
                    whereas any 1-layer Transformer without positional information cannot entirely solve it. 
                    We also demonstrate that position coupling can be applied to other algorithmic tasks such as addition with multiple summands, Nx2 multiplication, copy/reverse, 
                    and a two-dimensional task.
                </p>
            </div>
        </div>
    </div>
    <br>

    <br>
    <h1>Students' Oral Presentation #2</h1>
            <div class="session-box">
            <div class="session-box">
                <div class="session-info">
                    <h3>Talk #1 (Jaewook Lee): Exploiting Coordinate Structures in Optimization Problems
                </div>
                <div class="abstract">
                    <h4>Abstract:</h4>
                    <p>
                        This talk will be about research topics related to the coordinate structures of optimization problems I am currently working on. 
                        I will mainly introduce my recent work on minimax optimization, where we can see that alternating updates between the min/max coordinate blocks 
                        can lead to faster global convergence rates and motivate new types of algorithms. 
                        We will also cover some extended results and possible future directions, including applying a similar perspective to coordinate descent problems. 
                        If we have time, I would also like to lightly introduce several other research directions related to coordinate descent.
                    </p>
                </div>
            </div>

            <div class="session-box">
                <div class="session-info">
                    <h3>Talk #2 (TaeHo Yoon): Optimal Acceleration for Minimax and Fixed-Point Problems is Not Unique (ICML '24 Spotlight)</h3>
                </div>
                <div class="abstract">
                    <h4>Abstract:</h4>
                    <p>
                        Recently, accelerated algorithms using the anchoring mechanism for minimax optimization and fixed-point problems have been proposed, 
                        and matching complexity lower bounds establish their optimality. 
                        In this work, we present the surprising observation that the optimal acceleration mechanism in minimax optimization and fixed-point problems 
                        is not unique. Our new algorithms achieve exactly the same worst-case convergence rates as existing anchor-based methods 
                        while using materially different acceleration mechanisms. 
                        Specifically, these new algorithms are dual to the prior anchor-based accelerated methods in the sense of H-duality. 
                        This finding opens a new avenue of research on accelerated algorithms since we now have a family of methods that 
                        empirically exhibit varied characteristics while having the same optimal worst-case guarantee.
                        This is a joint work with Dr. Shuvomoy Das Gupta (MIT ORC &#8594; Columbia IEOR) and Prof. Ernest. K. Ryu (SNU Math), and is available at <a href="https://openreview.net/forum?id=ZeF75iQcAc" target="_blank">https://openreview.net/forum?id=ZeF75iQcAc</a>.
                    </p>
                </div>
            </div>

            <div class="session-box">
                <div class="session-info">
                    <h3>Talk #3 (Taehyun Hwang): Lasso Bandit with Compatibility Condition on Optimal Arm</h3>
                </div>
                <div class="abstract">
                    <h4>Abstract:</h4>
                    <p>
                        We consider a stochastic sparse linear bandit problem where only a sparse subset of context features affects the expected reward function, i.e., 
                        the unknown reward parameter has sparse structure. 
                        In the existing Lasso bandit literature, the compatibility conditions together with additional diversity conditions on the context features 
                        are imposed to achieve regret bounds that only depend logarithmically on the ambient dimension $d$. 
                        In this paper, we demonstrate that even without the additional diversity assumptions, the compatibility condition 
                        <i>only on the optimal arm</i> is sufficient to derive a regret bound that depends logarithmically on $d$, 
                        and our assumption is strictly weaker than those used in the lasso bandit literature under the single parameter setting. 
                        We propose an algorithm that adapts the forced-sampling technique and prove that the proposed algorithm achieves 
                        $\mathcal{O}(\text{poly}\log dT)$ regret under the margin condition. 
                        To our knowledge, the proposed algorithm requires the weakest assumptions among Lasso bandit algorithms under a single parameter setting 
                        that achieve $\mathcal{O}(\text{poly}\log dT)$ regret. 
                        Through the numerical experiments, we confirm the superior performance of our proposed algorithm.
                        This is a joint work with Harin Lee (Undergrad intern @ SNU DS) and Prof. Min-hwan Oh (SNU DS), and is available at <a href="https://arxiv.org/abs/2406.00823" target="_blank">https://arxiv.org/abs/2406.00823</a>.
                    </p>
                </div>
            </div>
    </div>
    <br>
</body>
</html>